{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNMTlD/r3dKdbP1UmBKM6DR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tnc-br/ddf_common/blob/gen_isoscape/generate_isoscape.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Variational Inference Isoscape Generation\n",
        "\n",
        "Use this file to generate isoscapes using the variational inference model."
      ],
      "metadata": {
        "id": "zAj3gGY4dWhN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_SAVE_LOCATION = \"/content/gdrive/MyDrive/amazon_rainforest_files/variational/model/kriging_numerical_stabilized/random_all_boosted_residuals.tf\"\n",
        "TRANSFORMER_SAVE_LOCATION = \"/content/gdrive/MyDrive/amazon_rainforest_files/variational/model/kriging_numerical_stabilized/random_all_boosted_residuals_transformer.pkl\"\n",
        "RUN_ID = 'variational_kriging_fixed_ablated_no_val_2023_08_03'\n",
        "\n",
        "# Only enable if you're using a good (i.e. non-hosted) machine for your runtime.\n",
        "GENERATE_MAX_RESOLUTION = True\n"
      ],
      "metadata": {
        "id": "Z411bUWuVAfG"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2Lwa0v2UPjB",
        "outputId": "bed80841-39a2-4db8-aa0a-e8f33ebc878e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "executing checkout_branch ...\n",
            "Branch main already checked out.\n",
            "Remember to reload your imports with `importlib.reload(module)`.\n",
            "b''\n",
            "main branch checked out as readonly. You may now use ddf_common imports\n"
          ]
        }
      ],
      "source": [
        "from osgeo import gdal, gdal_array\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from dataclasses import dataclass\n",
        "from typing import List\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import joblib\n",
        "import sys\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "!if [ ! -d \"/content/ddf_common_stub\" ] ; then git clone -b test https://github.com/tnc-br/ddf_common_stub.git; fi\n",
        "sys.path.append(\"/content/ddf_common_stub/\")\n",
        "import ddfimport\n",
        "ddfimport.ddf_import_common()\n",
        "\n",
        "import raster"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Iterating over brazilian landscape"
      ],
      "metadata": {
        "id": "CVOLCEqI2QtJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions_at_each_pixel(\n",
        "    model: tf.keras.Model,\n",
        "    feature_transformer: ColumnTransformer,\n",
        "    geotiffs: dict[str, raster.AmazonGeoTiff],\n",
        "    resolution: raster.Bounds):\n",
        "\n",
        "  # Initialize a blank plane representing means and variance.\n",
        "  predicted_means_np = np.ma.array(\n",
        "      np.zeros([resolution.raster_size_x, resolution.raster_size_y, 1], dtype=float),\n",
        "      mask=np.ones([resolution.raster_size_x, resolution.raster_size_y, 1], dtype=bool))\n",
        "  predicted_vars_np = np.ma.array(\n",
        "      np.zeros([resolution.raster_size_x, resolution.raster_size_y, 1], dtype=float),\n",
        "      mask=np.ones([resolution.raster_size_x, resolution.raster_size_y, 1], dtype=bool))\n",
        "\n",
        "  for x_idx, x in enumerate(tqdm(np.arange(resolution.minx, resolution.maxx, resolution.pixel_size_x, dtype=float))):\n",
        "    rows = []\n",
        "    row_indexes = []\n",
        "    for y_idx, y in enumerate(np.arange(resolution.miny, resolution.maxy, -resolution.pixel_size_y, dtype=float)):\n",
        "      # Row should contain all the features needed to predict, in the same\n",
        "      # column order the model was trained.\n",
        "      row = {}\n",
        "      row[\"lat\"] = y\n",
        "      row[\"long\"] = x\n",
        "\n",
        "      # Surround in try/except as we will be trying to fetch out of bounds data.\n",
        "      try:\n",
        "        for geotiff_label, geotiff in geotiffs.items():\n",
        "          row[geotiff_label] = raster.get_data_at_coords(geotiff, x, y, -1)\n",
        "          if pd.isnull(row[geotiff_label]):\n",
        "            raise ValueError\n",
        "      except (ValueError, IndexError):\n",
        "        continue # masked and out-of-bounds coordinates\n",
        "\n",
        "      rows.append(row)\n",
        "      row_indexes.append((y_idx,0,))\n",
        "\n",
        "    if (len(rows) > 0):\n",
        "      X = pd.DataFrame.from_dict(rows)\n",
        "      X_scaled = pd.DataFrame(feature_transformer.transform(X),\n",
        "                              index=X.index, columns=X.columns)\n",
        "      predictions = model.predict_on_batch(X_scaled)\n",
        "\n",
        "      means_np = predictions[:, 0]\n",
        "      for prediction, (y_idx, month_idx) in zip(means_np, row_indexes):\n",
        "        predicted_means_np.mask[x_idx,y_idx,month_idx] = False\n",
        "        predicted_means_np.data[x_idx,y_idx,month_idx] = prediction\n",
        "      vars_np = predictions[:, 1]\n",
        "      for prediction, (y_idx, month_idx) in zip (vars_np, row_indexes):\n",
        "        predicted_vars_np.mask[x_idx, y_idx, month_idx] = False\n",
        "        predicted_vars_np.data[x_idx, y_idx, month_idx] = prediction\n",
        "\n",
        "  return predicted_means_np, predicted_vars_np"
      ],
      "metadata": {
        "id": "AuKvm-scagjv"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import rasters"
      ],
      "metadata": {
        "id": "YF521ssLVbR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pet_geotiff = raster.load_named_raster(raster.get_raster_path(\"pet_Stack_mean.tiff\"), \"pet\")\n",
        "dem_geotiff = raster.load_named_raster(raster.get_raster_path(\"dem_pa_brasil_raster.tiff\"), \"dem\", use_only_band_index=0)\n",
        "pa_geotiff = raster.load_named_raster(raster.get_raster_path(\"dem_pa_brasil_raster.tiff\"), \"pa\", use_only_band_index=1)\n",
        "krig_means_geotiff = raster.load_named_raster(raster.get_raster_path(\"uc_davis_d18O_cel_ordinary_random_grouped_means.tiff\"), \"krig_means\")\n",
        "krig_variances_geotiff = raster.load_named_raster(raster.get_raster_path(\"uc_davis_d18O_cel_ordinary_random_grouped_vars.tiff\"), \"krig_variances\")\n",
        "\n",
        "# Note, the model inputs are order sensitive. These geotiffs should remain in this order.\n",
        "# We shouldn't rely on this and we should encode the column order with the saved model.\n",
        "feature_to_geotiff = {\n",
        "    \"VPD\" : raster.vapor_pressure_deficit_geotiff(),\n",
        "    \"RH\": raster.relative_humidity_geotiff(),\n",
        "    \"PET\": pet_geotiff,\n",
        "    \"DEM\": dem_geotiff,\n",
        "    \"PA\": pa_geotiff,\n",
        "    \"Mean Annual Temperature\" : raster.temperature_geotiff(),\n",
        "    \"Mean Annual Precipitation\" : raster.brazil_map_geotiff(),\n",
        "    \"ordinary_kriging_linear_d18O_predicted_mean\" : krig_means_geotiff,\n",
        "    \"ordinary_kriging_linear_d18O_predicted_variance\" : krig_variances_geotiff\n",
        "}"
      ],
      "metadata": {
        "id": "1zoCc3o8U_w3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Tensorflow model and scalers"
      ],
      "metadata": {
        "id": "JJXcXVDZbSgo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.saving.load_model(MODEL_SAVE_LOCATION)\n",
        "feature_transformer = joblib.load(TRANSFORMER_SAVE_LOCATION)"
      ],
      "metadata": {
        "id": "36Aeo8B5bVOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating isoscapes"
      ],
      "metadata": {
        "id": "m269sfakdQzp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resolution = raster.get_extent(pet_geotiff.gdal_dataset)\n",
        "\n",
        "# Get the biggest resolution from the input geotiffs.\n",
        "if GENERATE_MAX_RESOLUTION:\n",
        "  all_bounds = [raster.get_extent(geotiff.gdal_dataset) for geotiff in feature_to_geotiff.values()]\n",
        "  resolution = sorted(all_bounds, key=lambda bounds: bounds.pixel_size_x*bounds.pixel_size_y)[-1]\n",
        "\n",
        "def generate_isoscapes_from_variational_model(\n",
        "    model: tf.keras.Model,\n",
        "    feature_transformer: ColumnTransformer,\n",
        "    input_geotiffs: dict[str, raster.AmazonGeoTiff],\n",
        "    resolution: raster.Bounds):\n",
        "  means_np, vars_np = get_predictions_at_each_pixel(\n",
        "    model, feature_transformer, input_geotiffs, resolution)\n",
        "  raster.save_numpy_to_geotiff(\n",
        "      resolution, means_np, raster.get_raster_path(RUN_ID+\"_means.tiff\"))\n",
        "  raster.save_numpy_to_geotiff(\n",
        "      resolution, vars_np, raster.get_raster_path(RUN_ID+\"_vars.tiff\"))\n",
        "\n",
        "generate_isoscapes_from_variational_model(\n",
        "    model, feature_transformer, feature_to_geotiff, resolution)"
      ],
      "metadata": {
        "id": "nLwdaqCq1rLl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}